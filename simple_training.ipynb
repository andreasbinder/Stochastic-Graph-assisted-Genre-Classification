{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    },
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7efbe9f73d50>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# from torchtext.legacy import data\n",
    "import spacy\n",
    "# import en_core_web_sm\n",
    "\n",
    "from src.tdde13.data_handling import * #preprocess, preprocess_text, create_adjacency_matrix, create_label_lookup\n",
    "from src.tdde13.lstm import LSTM\n",
    "# , exclude=[\"ner\", \"parser\"]\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\", \"parser\"])\n",
    "\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit reviews arbeiten\n",
    "# wer k√∂nnten mit nlp gearbeitet haben? John?\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/book_reviews/finalv2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(pd.read_csv('datasets/book_reviews/final.csv', chunksize=10)))\n",
    "df = pd.read_csv('datasets/book_reviews/finalv2.csv')\n",
    "# df5000 = df[:5000]\n",
    "df_subset = df[:10000]\n",
    "\n",
    "load = True\n",
    "if load:\n",
    "    with open('objs10000.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "        desc, vocab, word_to_ix = pickle.load(f)\n",
    "else:\n",
    "    desc, vocab, word_to_ix = preprocess_text(nlp, df10000.description)\n",
    "    with open('objs5000.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump([desc, vocab, word_to_ix], f)\n",
    "\n",
    "label_to_idx = create_label_lookup(df_subset)\n",
    "clean_desc, labels = remove_empty_descriptions(desc, df_subset.genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[:10000]\n",
    "clean_desc, labels = remove_empty_descriptions(desc, df_subset.genres)\n",
    "padded_desc, max_len = pad_sequence(clean_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train, idx_val, idx_test = split(labels=labels, train_size=0.6, val_size=0.2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([['Davey', 'feel', 'life', ..., '<pad>', '<pad>', '<pad>'],\n       ['blind', 'miserable', 'able', ..., '<pad>', '<pad>', '<pad>'],\n       ['New', 'York', 'Timesbestselling', ..., '<pad>', '<pad>',\n        '<pad>'],\n       ...,\n       ['year', 'Annabel', 'girl', ..., '<pad>', '<pad>', '<pad>'],\n       ['straight', 'library', 'strange', ..., '<pad>', '<pad>', '<pad>'],\n       ['take', 'bite', 'Big', ..., '<pad>', '<pad>', '<pad>']],\n      dtype=object)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_desc[idx_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([['Lina', 'like', 'year', ..., '<pad>', '<pad>', '<pad>'],\n       ['year', 'world', 'bleak', ..., '<pad>', '<pad>', '<pad>'],\n       ['Time', 'City', 'build', ..., '<pad>', '<pad>', '<pad>'],\n       ...,\n       ['eighteen', 'year', 'old', ..., '<pad>', '<pad>', '<pad>'],\n       ['friend', 'benefit', 'read', ..., '<pad>', '<pad>', '<pad>'],\n       ['Adam', 'kindly', 'leader', ..., '<pad>', '<pad>', '<pad>']],\n      dtype=object)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_desc[idx_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([['Humphrey', 'Wescott', 'Earl', ..., '<pad>', '<pad>', '<pad>'],\n       ['Sadie', 'Turner', 'organize', ..., '<pad>', '<pad>', '<pad>'],\n       ['belong', 'wild', 'fantasy', ..., '<pad>', '<pad>', '<pad>'],\n       ...,\n       ['Clementine', 'DeVore', 'spend', ..., '<pad>', '<pad>', '<pad>'],\n       ['Neal', 'Barton', 'want', ..., '<pad>', '<pad>', '<pad>'],\n       ['Sally', 'Paul', 'penny', ..., '<pad>', '<pad>', '<pad>']],\n      dtype=object)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_desc[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[3,5,1,2],[3,1,5,3],[7,5,8,3]],dtype=torch.float)\n",
    "print(tensor)\n",
    "tensor.apply_(lambda x: (x+0.2))\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html\n",
    "'''from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "x_seq = [[5, 18, 29], [32, 100], [699, 6, 9, 17]]\n",
    "x_padded = pad_sequence(x_seq, batch_first=True, padding_value=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(labels).value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(labels).iloc[idx_train.tolist(), :].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(labels).iloc[idx_val.tolist(), :].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_descriptions = torch.tensor([[word_to_ix[word] for word in d] for d in padded_desc])\n",
    "enc_labels = torch.tensor([label_to_idx[label] for label in labels]).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = enc_descriptions[idx_test]\n",
    "label = enc_labels[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the predictions of the MLP\n",
    "# maybe truncate long sentences\n",
    "# over/undersampling\n",
    "# more sophisticated preprocessing\n",
    "predictions = lstm(batch).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(6)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18645/65772444.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx_to_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type str)"
     ]
    }
   ],
   "source": [
    "predictions.apply_(lambda x: idx_to_label[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "              mystery, thriller, crime       0.36      0.13      0.19        63\n",
      "                           non-fiction       0.00      0.00      0.00        16\n",
      "                       comics, graphic       0.50      0.10      0.17        30\n",
      "                              children       0.00      0.00      0.00         6\n",
      "                           young-adult       0.34      0.39      0.36       175\n",
      "history, historical fiction, biography       0.50      0.09      0.15        22\n",
      "                               romance       0.57      0.61      0.59       246\n",
      "                               fiction       0.31      0.36      0.34       191\n",
      "                                poetry       0.00      0.00      0.00         1\n",
      "                   fantasy, paranormal       0.46      0.53      0.50       240\n",
      "\n",
      "                              accuracy                           0.43       990\n",
      "                             macro avg       0.31      0.22      0.23       990\n",
      "                          weighted avg       0.42      0.43      0.42       990\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreas/anaconda3/envs/tdde13/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(label, predictions.numpy(), target_names=list(label_to_idx.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "              mystery, thriller, crime       1.00      1.00      1.00       505\n",
      "                           non-fiction       1.00      1.00      1.00       124\n",
      "                       comics, graphic       1.00      1.00      1.00       243\n",
      "                              children       1.00      1.00      1.00        49\n",
      "                           young-adult       1.00      1.00      1.00      1397\n",
      "history, historical fiction, biography       1.00      1.00      1.00       180\n",
      "                               romance       1.00      1.00      1.00      1965\n",
      "                               fiction       1.00      1.00      1.00      1525\n",
      "                                poetry       1.00      1.00      1.00        10\n",
      "                   fantasy, paranormal       1.00      1.00      1.00      1914\n",
      "\n",
      "                              accuracy                           1.00      7912\n",
      "                             macro avg       1.00      1.00      1.00      7912\n",
      "                          weighted avg       1.00      1.00      1.00      7912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# what are the predictions of the MLP\n",
    "# maybe truncate long sentences\n",
    "\n",
    "prediction_train = lstm(enc_descriptions[idx_train]).argmax(axis=1)\n",
    "label_train = enc_labels[idx_train]\n",
    "print(classification_report(label_train, prediction_train.numpy(), target_names=list(label_to_idx.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18645/1063314413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx_to_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type str)"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(predictions.apply_(lambda x: idx_to_label[x]).numpy()).value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'mystery, thriller, crime': 0,\n 'non-fiction': 1,\n 'comics, graphic': 2,\n 'children': 3,\n 'young-adult': 4,\n 'history, historical fiction, biography': 5,\n 'romance': 6,\n 'fiction': 7,\n 'poetry': 8,\n 'fantasy, paranormal': 9}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_label = dict(zip(label_to_idx.values(), label_to_idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['fresh', 'fun', 'repackage', 'Wild', 'Cards', 'well',\n       'Perfectlaunches', 'romantic', 'new', 'series', 'NY',\n       'Timesbestselling', 'author', 'Simone', 'Elkeles', 'get', 'kick',\n       'boarding', 'school', 'bad', 'boy', 'Derek', 'Fitzpatrick',\n       'choice', 'live', 'ditzy', 'stepmother', 'military', 'dad',\n       'deploy', 'thing', 'quickly', 'bad', 'bad', 'find', 'plan',\n       'childhood', 'home', 'Illinois', 'Derek', 'counting', 'day',\n       'thing', 'need', 'involve', 'family', 'drama', 'Ashtyn', 'Parker',\n       'know', 'thing', 'certain', 'people', 'care', 'leave', 'backward',\n       'glance', 'old', 'sister', 'come', 'home', 'abandon', 'year',\n       'early', 'hot', 'new', 'stepson', 'tow', 'Ashtyn', 'want', 'come',\n       'plan', 'finally', 'chance', 'leave', 'require', 'trust', 'Derek',\n       'barely', 'know', 'bear', 'break', 'rule', 'willing', 'heart',\n       'line', 'try', 'future', 'want', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>',\n       '<pad>'], dtype=object)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_desc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode Description\n",
      "Epoch: 0\n",
      "Train Loss: 86.7609 Train Acc 0.260 Val Loss 28.4830 Val Acc 0.268\n",
      "Epoch: 1\n",
      "Train Loss: 77.9744 Train Acc 0.351 Val Loss 28.2019 Val Acc 0.290\n",
      "Epoch: 2\n",
      "Train Loss: 73.2569 Train Acc 0.426 Val Loss 28.2310 Val Acc 0.274\n",
      "Epoch: 3\n",
      "Train Loss: 68.6127 Train Acc 0.502 Val Loss 28.0607 Val Acc 0.296\n",
      "Epoch: 4\n",
      "Train Loss: 64.5757 Train Acc 0.542 Val Loss 27.8488 Val Acc 0.302\n",
      "Epoch: 5\n",
      "Train Loss: 60.7472 Train Acc 0.580 Val Loss 27.9713 Val Acc 0.294\n",
      "Epoch: 6\n",
      "Train Loss: 57.0952 Train Acc 0.612 Val Loss 28.1256 Val Acc 0.302\n",
      "Epoch: 7\n",
      "Train Loss: 53.7181 Train Acc 0.642 Val Loss 28.1880 Val Acc 0.305\n",
      "Epoch: 8\n",
      "Train Loss: 50.5277 Train Acc 0.668 Val Loss 28.4793 Val Acc 0.308\n",
      "Epoch: 9\n",
      "Train Loss: 47.7426 Train Acc 0.686 Val Loss 28.7887 Val Acc 0.311\n",
      "Epoch: 10\n",
      "Train Loss: 44.9336 Train Acc 0.713 Val Loss 28.9648 Val Acc 0.303\n",
      "Epoch: 11\n",
      "Train Loss: 42.6001 Train Acc 0.733 Val Loss 29.3599 Val Acc 0.312\n",
      "Epoch: 12\n",
      "Train Loss: 40.5582 Train Acc 0.750 Val Loss 29.6456 Val Acc 0.303\n",
      "Epoch: 13\n",
      "Train Loss: 38.6985 Train Acc 0.761 Val Loss 29.8378 Val Acc 0.313\n",
      "Epoch: 14\n",
      "Train Loss: 36.7253 Train Acc 0.776 Val Loss 30.1824 Val Acc 0.310\n",
      "Finished Training\n",
      "Final Test Acc: 0.331\n"
     ]
    }
   ],
   "source": [
    "# 987 X 1: 231sec\n",
    "\n",
    "from src.tdde13.lstm import LSTM\n",
    "lstm = LSTM(len(vocab), max_len, use_glove=True)\n",
    "lstm.train_lstm(padded_desc, labels, vocab, word_to_ix, label_to_idx, idx_train, idx_val, idx_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tdde13': conda)",
   "name": "python3812jvsc74a57bd0b5d3780335a600d2b64d22f19b7dc7c5025d01ebed9cb50cd08aeee3fa28229c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "b5d3780335a600d2b64d22f19b7dc7c5025d01ebed9cb50cd08aeee3fa28229c"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}