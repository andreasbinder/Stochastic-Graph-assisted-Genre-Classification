{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/andreas/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:635493)",
      "at w.execute (/home/andreas/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:634882)",
      "at w.start (/home/andreas/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:629791)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:97:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/andreas/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:644977)",
      "at async t.CellExecutionQueue.start (/home/andreas/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:644517)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# from torchtext.legacy import data\n",
    "import spacy\n",
    "# import en_core_web_sm\n",
    "\n",
    "from src.tdde13.data_handling import * #preprocess, preprocess_text, create_adjacency_matrix, create_label_lookup\n",
    "from src.tdde13.lstm import LSTM\n",
    "# , exclude=[\"ner\", \"parser\"]\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\", \"parser\"])\n",
    "\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit reviews arbeiten\n",
    "# wer k√∂nnten mit nlp gearbeitet haben? John?\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/book_reviews/finalv2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(pd.read_csv('datasets/book_reviews/final.csv', chunksize=10)))\n",
    "df = pd.read_csv('datasets/book_reviews/finalv2.csv')\n",
    "# df5000 = df[:5000]\n",
    "df_subset = df[2000:8000]\n",
    "\n",
    "load = True\n",
    "if load:\n",
    "    with open('preprocessed_reviews_2K-8K.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "        desc, vocab, word_to_ix = pickle.load(f)\n",
    "else:\n",
    "    desc, vocab, word_to_ix = preprocess_text(nlp, df10000.description)\n",
    "    with open('objs5000.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump([desc, vocab, word_to_ix], f)\n",
    "\n",
    "label_to_idx = create_label_lookup(df_subset)\n",
    "clean_desc, labels = remove_empty_descriptions(desc, df_subset.genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[2000:8000]\n",
    "with open('objs10000.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    descriptions, descriptions_vocab, descriptions_word_to_ix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "             'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "     categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_desc, labels = remove_empty_descriptions(desc, df_subset.genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_length = 2000\n",
    "clean_desc = np.array([text[:cut_length] for text in clean_desc], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subset = df[:10000]\n",
    "clean_desc, labels = remove_empty_descriptions(desc, df_subset.genres)\n",
    "padded_desc, max_len = pad_sequence(clean_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train, idx_val, idx_test = split(labels=labels, train_size=0.6, val_size=0.2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "9892\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(7913, 42003)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/andreas/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:635493)",
      "at w.execute (/home/andreas/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:634882)",
      "at w.start (/home/andreas/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:629791)",
      "at processTicksAndRejections (internal/process/task_queues.js:97:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/andreas/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:644977)",
      "at async t.CellExecutionQueue.start (/home/andreas/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:644517)"
     ]
    }
   ],
   "source": [
    "from src.tdde13.baselines import MLP\n",
    "\n",
    "input_size = X_train_transformed.shape[1]\n",
    "output_size = 10\n",
    "\n",
    "mlp = MLP(input_size, output_size)\n",
    "\n",
    "mlp.train_mlp(X_train_transformed, X_test_transformed, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(7913, 42003)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "42003"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "                              children       0.00      0.00      0.00         9\n",
      "                       comics, graphic       0.57      0.08      0.13        53\n",
      "                   fantasy, paranormal       0.68      0.80      0.73       484\n",
      "                               fiction       0.66      0.73      0.69       390\n",
      "history, historical fiction, biography       0.00      0.00      0.00        48\n",
      "              mystery, thriller, crime       0.96      0.18      0.31       143\n",
      "                           non-fiction       0.00      0.00      0.00        31\n",
      "                                poetry       0.00      0.00      0.00         2\n",
      "                               romance       0.64      0.90      0.75       467\n",
      "                           young-adult       0.65      0.51      0.57       352\n",
      "\n",
      "                              accuracy                           0.66      1979\n",
      "                             macro avg       0.42      0.32      0.32      1979\n",
      "                          weighted avg       0.65      0.66      0.62      1979\n",
      "\n",
      "0.6584133400707428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreas/anaconda3/envs/tdde13/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer # we could have use TfidfVectorizer too. From sklearn doc : \"tf-idf vectors are also known to work well in practice\"\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pipe = Pipeline([('vectorizer', CountVectorizer()), ('nbm', MultinomialNB())])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "preds = pipe.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(labels).iloc[idx_val.tolist(), :].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_descriptions = torch.tensor([[word_to_ix[word] for word in d] for d in padded_desc])\n",
    "enc_labels = torch.tensor([label_to_idx[label] for label in labels]).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18645/65772444.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx_to_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type str)"
     ]
    }
   ],
   "source": [
    "predictions.apply_(lambda x: idx_to_label[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(label, predictions.numpy(), target_names=list(label_to_idx.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# what are the predictions of the MLP\n",
    "# maybe truncate long sentences\n",
    "\n",
    "prediction_train = lstm(enc_descriptions[idx_train]).argmax(axis=1)\n",
    "label_train = enc_labels[idx_train]\n",
    "print(classification_report(label_train, prediction_train.numpy(), target_names=list(label_to_idx.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining\n",
      "Splitting\n",
      "Encode Description\n",
      "Epoch: 0\n"
     ]
    }
   ],
   "source": [
    "# 987 X 1: 231sec\n",
    "# max_len = 5000\n",
    "\n",
    "# padded_desc = clean_desc\n",
    "\n",
    "padded_desc, labels, vocab, word_to_ix, label_to_idx, idx_train, idx_val, idx_test = load_reviews_and_descriptions()\n",
    "max_len = max([len(x) for x in padded_desc])\n",
    "from src.tdde13.lstm import LSTM\n",
    "lstm = LSTM(len(vocab), max_len, use_glove=True)\n",
    "lstm.train_lstm(padded_desc, labels, vocab, word_to_ix, label_to_idx, idx_train, idx_val, idx_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tdde13': conda)",
   "name": "python3812jvsc74a57bd0b5d3780335a600d2b64d22f19b7dc7c5025d01ebed9cb50cd08aeee3fa28229c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "b5d3780335a600d2b64d22f19b7dc7c5025d01ebed9cb50cd08aeee3fa28229c"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}